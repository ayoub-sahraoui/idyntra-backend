from fastapi import FastAPI, File, UploadFile, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.concurrency import run_in_threadpool
from fastapi.responses import JSONResponse
from fastapi.exception_handlers import http_exception_handler
from pydantic import BaseModel
import re
from typing import Dict, Any, Optional, List, Tuple
import uvicorn
import cv2
import numpy as np
import os
import sys
from PIL import Image
import io
import uuid
from datetime import datetime, timezone
import json
import subprocess
import threading
import time
import logging
from logging.handlers import RotatingFileHandler
import psutil
import tempfile
from dataclasses import dataclass
from enum import Enum

# ============================================================================
# CPU configuration and environment controls
# ============================================================================
CPU_ONLY = os.environ.get('CPU_ONLY', '0').lower() in ('1', 'true', 'yes')
if CPU_ONLY:
    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
    os.environ['DLIB_USE_CUDA'] = '0'

# Setup structured logging
LOG_FILE = os.environ.get('IDV_LOG_FILE', 'idv_api.log')
logger = logging.getLogger('idv_api')
logger.setLevel(logging.INFO)
handler = RotatingFileHandler(LOG_FILE, maxBytes=5 * 1024 * 1024, backupCount=3)
formatter = logging.Formatter('%(asctime)s %(levelname)s [%(name)s] %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)
console = logging.StreamHandler(sys.stdout)
console.setFormatter(formatter)
logger.addHandler(console)

logger.info("Initializing Enhanced ID Verification API")

# RECOMMENDED MRZ Libraries
try:
    from readmrz import MrzDetector, MrzReader
    readmrz_available = True
    logger.info("âœ“ ReadMRZ available (RECOMMENDED)")
except Exception:
    readmrz_available = False
    logger.warning("âš  ReadMRZ not available - install with: pip install readmrz")

try:
    import passport_mrz_extractor
    passport_mrz_extractor_available = True
    logger.info("âœ“ passport-mrz-extractor available (RECOMMENDED)")
except Exception:
    passport_mrz_extractor_available = False
    logger.warning("âš  passport-mrz-extractor not available - install with: pip install passport-mrz-extractor")

# Import face_recognition with error handling
try:
    import face_recognition
    logger.info("âœ“ face_recognition loaded (CPU mode)")
except RuntimeError as e:
    if "cuda" in str(e).lower():
        logger.error("CUDA error detected during import")
        sys.exit(1)
    raise

# Import ML / NLP libraries
from transformers import AutoImageProcessor, AutoModelForImageClassification
import torch
from skimage.feature import local_binary_pattern
from scipy import ndimage
import nest_asyncio

GPU_AVAILABLE = False if CPU_ONLY else (torch.cuda.is_available() and torch.cuda.device_count() > 0)
DEVICE_MODE = "cuda" if GPU_AVAILABLE else "cpu"

if GPU_AVAILABLE:
    logger.info(f"ðŸš€ GPU detected: {torch.cuda.get_device_name(0)}")
else:
    logger.info("ðŸ’» Running in CPU mode")


# ============================================================================
# ENHANCED CONFIGURATION
# ============================================================================
@dataclass
class VerificationConfig:
    """Enhanced configuration with graduated thresholds"""
    
    # Liveness thresholds
    liveness_score_min: float = 0.65
    liveness_score_high: float = 0.80
    blur_threshold: float = 100.0
    
    # Face matching thresholds
    face_match_confidence_min: float = 70.0
    face_match_confidence_high: float = 85.0
    face_match_tolerance: float = 0.5
    
    # Document authenticity
    authenticity_score_min: float = 60.0
    authenticity_score_high: float = 75.0
    
    # Deepfake
    deepfake_confidence_min: float = 0.70
    
    # Image quality
    image_quality_min: float = 60.0
    
    # Risk-based
    enable_risk_based_auth: bool = True


class VerificationStatus(Enum):
    """Verification result statuses"""
    APPROVED = "approved"
    REJECTED = "rejected"
    MANUAL_REVIEW = "manual_review"
    ERROR = "error"


config = VerificationConfig()


# ============================================================================
# ADVANCED LIVENESS DETECTOR
# ============================================================================
class AdvancedLivenessDetector:
    """Multi-modal liveness detection with anti-spoofing"""
    
    def __init__(self):
        self.thresholds = {
            'blur_threshold': config.blur_threshold,
            'face_size_min': 80,
            'face_size_max': 800,
            'specular_reflection_min': 20.0,
            'micro_texture_score_min': 0.15,
            'depth_cue_score_min': 0.3,
            'fourier_high_freq_max': 8e9,
            'liveness_score_threshold': config.liveness_score_min
        }
    
    def comprehensive_check(self, image: np.ndarray, face_location: Tuple = None) -> Dict:
        """Run all liveness checks"""
        results = {}
        
        try:
            # Find face if not provided
            if face_location is None:
                face_locations = face_recognition.face_locations(image, model='hog')
                if not face_locations:
                    return {
                        'is_live': False,
                        'liveness_score': 0.0,
                        'error': 'No face detected',
                        'checks': {}
                    }
                face_location = face_locations[0]
            
            # Run all checks
            results['blur_check'] = self._check_blur(image)
            results['specular_reflection'] = self._detect_specular_reflections(image, face_location)
            results['micro_texture'] = self._analyze_micro_texture(image)
            results['print_attack'] = self._detect_print_attack(image)
            results['depth_cues'] = self._estimate_depth_cues(image)
            results['face_proportions'] = self._check_face_proportions(face_location, image.shape)
            
            # Calculate aggregate score
            checks_passed = sum(1 for check in results.values() if check.get('passed', False))
            total_checks = len(results)
            liveness_score = checks_passed / total_checks if total_checks > 0 else 0.0
            
            is_live = liveness_score >= self.thresholds['liveness_score_threshold']
            
            return {
                'is_live': bool(is_live),
                'liveness_score': float(liveness_score),
                'checks_passed': f"{checks_passed}/{total_checks}",
                'checks': results,
                'confidence': 'high' if liveness_score > 0.8 else 'medium' if liveness_score > 0.65 else 'low'
            }
            
        except Exception as e:
            logger.exception(f"Liveness check error: {e}")
            return {
                'is_live': False,
                'liveness_score': 0.0,
                'error': str(e),
                'checks': {}
            }
    
    def _check_blur(self, image: np.ndarray) -> Dict:
        """Blur detection using Laplacian variance"""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
        blur_score = float(cv2.Laplacian(gray, cv2.CV_64F).var())
        passed = blur_score > self.thresholds['blur_threshold']
        return {'blur_score': float(blur_score), 'passed': bool(passed)}
    
    def _detect_specular_reflections(self, image: np.ndarray, face_location: Tuple) -> Dict:
        """Detect eye reflections (real faces have them)"""
        try:
            top, right, bottom, left = face_location
            eye_region = image[top:top + int((bottom - top) * 0.4), left:right]
            
            gray = cv2.cvtColor(eye_region, cv2.COLOR_BGR2GRAY) if len(eye_region.shape) == 3 else eye_region
            _, bright_spots = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)
            
            reflection_score = float(np.sum(bright_spots > 0) / bright_spots.size * 100)
            has_reflection = reflection_score > self.thresholds['specular_reflection_min']
            
            return {
                'has_reflection': bool(has_reflection),
                'reflection_score': float(reflection_score),
                'passed': bool(has_reflection)
            }
        except Exception as e:
            return {'has_reflection': False, 'passed': False, 'error': str(e)}
    
    def _analyze_micro_texture(self, image: np.ndarray) -> Dict:
        """Analyze micro-texture patterns"""
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
            lbp = local_binary_pattern(gray, P=8, R=1, method='uniform')
            
            hist, _ = np.histogram(lbp.ravel(), bins=59, range=(0, 59))
            hist = hist.astype(float) / hist.sum()
            hist = hist[hist > 0]
            entropy = float(-np.sum(hist * np.log2(hist)))
            
            normalized_score = entropy / 5.9
            passed = normalized_score > self.thresholds['micro_texture_score_min']
            
            return {
                'micro_texture_score': float(normalized_score),
                'entropy': float(entropy),
                'passed': bool(passed)
            }
        except Exception as e:
            return {'micro_texture_score': 0.0, 'passed': False, 'error': str(e)}
    
    def _detect_print_attack(self, image: np.ndarray) -> Dict:
        """Detect print/photo attacks using frequency analysis"""
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
            
            fft = np.fft.fft2(gray)
            fft_shift = np.fft.fftshift(fft)
            magnitude = np.abs(fft_shift)
            
            h, w = magnitude.shape
            center = (h // 2, w // 2)
            
            high_freq_mask = np.zeros((h, w), dtype=np.uint8)
            cv2.circle(high_freq_mask, center, min(h, w) // 4, 255, -1)
            high_freq_mask = high_freq_mask.astype(bool)
            
            high_freq_energy = float(np.sum(magnitude * high_freq_mask))
            peaks = magnitude > np.percentile(magnitude, 99.5)
            peak_count = int(np.sum(peaks))
            
            is_print = high_freq_energy > self.thresholds['fourier_high_freq_max'] or peak_count > 50
            
            return {
                'is_print_attack': bool(is_print),
                'high_freq_energy': float(high_freq_energy),
                'peak_count': int(peak_count),
                'passed': bool(not is_print)
            }
        except Exception as e:
            return {'is_print_attack': True, 'passed': False, 'error': str(e)}
    
    def _estimate_depth_cues(self, image: np.ndarray) -> Dict:
        """Estimate depth - flat photos lack depth variation"""
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
            
            sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
            sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            gradient_magnitude = np.sqrt(sobelx**2 + sobely**2)
            
            gradient_std = float(np.std(gradient_magnitude))
            gradient_mean = float(np.mean(gradient_magnitude))
            
            depth_score = gradient_std / gradient_mean if gradient_mean > 0 else 0.0
            depth_score = min(depth_score / 2.0, 1.0)
            
            passed = depth_score > self.thresholds['depth_cue_score_min']
            
            return {
                'depth_score': float(depth_score),
                'passed': bool(passed)
            }
        except Exception as e:
            return {'depth_score': 0.0, 'passed': False, 'error': str(e)}
    
    def _check_face_proportions(self, face_location: Tuple, image_shape: Tuple) -> Dict:
        """Validate face size and position"""
        try:
            top, right, bottom, left = face_location
            face_width = right - left
            face_height = bottom - top
            img_height, img_width = image_shape[:2]
            
            size_valid = (
                self.thresholds['face_size_min'] < face_width < self.thresholds['face_size_max'] and
                self.thresholds['face_size_min'] < face_height < self.thresholds['face_size_max']
            )
            
            face_area = face_width * face_height
            image_area = img_width * img_height
            face_ratio = face_area / image_area if image_area > 0 else 0
            ratio_valid = 0.05 < face_ratio < 0.7
            
            aspect_ratio = face_height / face_width if face_width > 0 else 0
            aspect_valid = 0.9 < aspect_ratio < 1.6
            
            return {
                'size_valid': bool(size_valid),
                'ratio_valid': bool(ratio_valid),
                'aspect_valid': bool(aspect_valid),
                'passed': bool(size_valid and ratio_valid and aspect_valid)
            }
        except Exception as e:
            return {'passed': False, 'error': str(e)}


# ============================================================================
# ENSEMBLE FACE MATCHER
# ============================================================================
class EnsembleFaceMatcher:
    """Multi-model face matching for higher accuracy"""
    
    def __init__(self, use_gpu: bool = False):
        self.use_gpu = use_gpu
        self.models_loaded = {'face_recognition': True}
        self.face_recognition = face_recognition
        logger.info("âœ“ EnsembleFaceMatcher initialized with face_recognition")
    
    def ensemble_match(
        self,
        id_image: np.ndarray,
        selfie_image: np.ndarray,
        strategy: str = 'weighted_vote'
    ) -> Dict:
        """Match faces with ensemble approach"""
        results = {}
        
        # Primary: face_recognition
        results['face_recognition'] = self._match_with_face_recognition(
            id_image, selfie_image, tolerance=config.face_match_tolerance
        )
        
        # Calculate overall confidence
        confidence = results['face_recognition'].get('confidence', 0)
        matched = results['face_recognition'].get('matched', False)
        
        return {
            'matched': bool(matched),
            'confidence': float(confidence),
            'strategy': strategy,
            'models_used': ['face_recognition'],
            'individual_results': results
        }
    
    def _match_with_face_recognition(
        self, 
        id_image: np.ndarray, 
        selfie_image: np.ndarray,
        tolerance: float = 0.5
    ) -> Dict:
        """Match using face_recognition (dlib)"""
        try:
            id_rgb = cv2.cvtColor(id_image, cv2.COLOR_BGR2RGB)
            selfie_rgb = cv2.cvtColor(selfie_image, cv2.COLOR_BGR2RGB)
            
            id_locations = self.face_recognition.face_locations(id_rgb, model='hog')
            selfie_locations = self.face_recognition.face_locations(selfie_rgb, model='hog')
            
            if not id_locations or not selfie_locations:
                return {
                    'available': True,
                    'matched': False,
                    'confidence': 0.0,
                    'error': 'Face not detected in one or both images'
                }
            
            id_encoding = self.face_recognition.face_encodings(id_rgb, id_locations)[0]
            selfie_encoding = self.face_recognition.face_encodings(selfie_rgb, selfie_locations)[0]
            
            distance = float(self.face_recognition.face_distance([id_encoding], selfie_encoding)[0])
            matched = bool(distance <= tolerance)
            confidence = float((1 - distance) * 100)
            
            return {
                'available': True,
                'matched': matched,
                'distance': distance,
                'confidence': confidence,
                'threshold_used': tolerance
            }
        except Exception as e:
            logger.exception(f"Face matching failed: {e}")
            return {'available': True, 'matched': False, 'confidence': 0.0, 'error': str(e)}
    
    def get_quality_metrics(self, image: np.ndarray) -> Dict:
        """Assess image quality"""
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            sharpness = float(cv2.Laplacian(gray, cv2.CV_64F).var())
            brightness = float(np.mean(gray))
            contrast = float(np.std(gray))
            height, width = image.shape[:2]
            resolution = height * width
            
            sharpness_score = min(sharpness / 500.0, 1.0) * 100
            brightness_score = (1 - abs(brightness - 127) / 127) * 100
            contrast_score = min(contrast / 64.0, 1.0) * 100
            resolution_score = min(resolution / (640 * 480), 1.0) * 100
            
            overall_quality = (sharpness_score + brightness_score + contrast_score + resolution_score) / 4
            
            return {
                'sharpness': float(sharpness),
                'brightness': float(brightness),
                'contrast': float(contrast),
                'resolution': int(resolution),
                'quality_score': float(overall_quality),
                'is_good_quality': bool(overall_quality >= config.image_quality_min)
            }
        except Exception as e:
            return {'is_good_quality': False, 'error': str(e)}


# ============================================================================
# DOCUMENT AUTHENTICITY CHECKER
# ============================================================================
class DocumentAuthenticityChecker:
    """Verify document authenticity"""
    
    def comprehensive_document_check(self, image: np.ndarray, structured_data: Optional[Dict] = None) -> Dict:
        """Run all document authenticity checks"""
        results = {}
        
        results['tampering'] = self._detect_tampering(image)
        
        if structured_data:
            results['data_consistency'] = self._check_data_consistency(structured_data)
            if expiry := structured_data.get('date_expiration'):
                results['expiry_validation'] = self._validate_expiry_date(expiry)
        
        checks_passed = sum(
            1 for check in results.values()
            if isinstance(check, dict) and check.get('passed', False)
        )
        total_checks = sum(
            1 for check in results.values()
            if isinstance(check, dict) and 'passed' in check
        )
        
        authenticity_score = (checks_passed / total_checks * 100) if total_checks > 0 else 50.0
        is_authentic = authenticity_score >= config.authenticity_score_min
        
        return {
            'is_authentic': bool(is_authentic),
            'authenticity_score': float(authenticity_score),
            'checks_passed': f"{checks_passed}/{total_checks}",
            'checks': results
        }
    
    def _detect_tampering(self, image: np.ndarray) -> Dict:
        """Detect document tampering"""
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
            
            # Noise uniformity check
            h, w = gray.shape
            grid_size = 4
            cell_h, cell_w = h // grid_size, w // grid_size
            
            noise_levels = []
            for i in range(grid_size):
                for j in range(grid_size):
                    cell = gray[i*cell_h:(i+1)*cell_h, j*cell_w:(j+1)*cell_w]
                    blurred = cv2.GaussianBlur(cell, (5, 5), 0)
                    noise = cv2.absdiff(cell, blurred)
                    noise_levels.append(float(np.std(noise)))
            
            uniformity = 1.0 - min(np.std(noise_levels) / (np.mean(noise_levels) + 1e-6), 1.0)
            is_tampered = uniformity < 0.7
            
            return {
                'is_tampered': bool(is_tampered),
                'uniformity': float(uniformity),
                'passed': bool(not is_tampered)
            }
        except Exception as e:
            return {'is_tampered': True, 'passed': False, 'error': str(e)}
    
    def _check_data_consistency(self, structured_data: Dict) -> Dict:
        """Validate data consistency"""
        issues = []
        
        try:
            if dob := structured_data.get('date_naissance'):
                try:
                    dob_date = datetime.strptime(dob, '%Y%m%d')
                    age = (datetime.now() - dob_date).days / 365.25
                    
                    if age < 0:
                        issues.append('Date of birth is in future')
                    elif age < 16:
                        issues.append('Person under 16')
                    elif age > 120:
                        issues.append('Person over 120')
                except:
                    issues.append('Invalid DOB format')
            
            is_consistent = len(issues) == 0
            
            return {
                'is_consistent': bool(is_consistent),
                'issues': issues,
                'passed': bool(is_consistent)
            }
        except Exception as e:
            return {'is_consistent': False, 'issues': [str(e)], 'passed': False}
    
    def _validate_expiry_date(self, expiry_date_str: str) -> Dict:
        """Validate document expiry"""
        try:
            date_formats = ['%Y%m%d', '%d%m%Y', '%Y-%m-%d']
            
            expiry_date = None
            for fmt in date_formats:
                try:
                    expiry_date = datetime.strptime(expiry_date_str, fmt)
                    break
                except ValueError:
                    continue
            
            if not expiry_date:
                return {'is_valid': False, 'status': 'invalid_format', 'passed': False}
            
            today = datetime.now()
            is_expired = expiry_date < today
            days_until_expiry = (expiry_date - today).days
            
            if is_expired:
                status = 'expired'
                is_valid = False
            elif days_until_expiry < 30:
                status = 'expiring_soon'
                is_valid = True
            else:
                status = 'valid'
                is_valid = True
            
            return {
                'is_valid': bool(is_valid),
                'status': status,
                'days_until_expiry': int(days_until_expiry),
                'passed': bool(is_valid)
            }
        except Exception as e:
            return {'is_valid': False, 'status': 'error', 'passed': False, 'error': str(e)}


# ============================================================================
# MRZ EXTRACTION - CLEAN VERSION (2 ENGINES ONLY)
# ============================================================================
def extract_text_from_image(image: np.ndarray) -> str:
    """Extract MRZ text using ReadMRZ and passport-mrz-extractor"""
    tmp_path = None
    try:
        with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as tmp:
            tmp_path = tmp.name
            success = cv2.imwrite(tmp_path, image, [cv2.IMWRITE_JPEG_QUALITY, 95])
            if not success:
                logger.error(f"Failed to save image to {tmp_path}")
                return ""

        # PRIORITY 1: Try ReadMRZ (auto-detects MRZ region)
        if readmrz_available:
            try:
                logger.info("Attempting ReadMRZ extraction...")
                detector = MrzDetector()
                reader = MrzReader()
                
                mrz_image = detector.read(tmp_path)
                if mrz_image is not None:
                    cropped = detector.crop_area(mrz_image)
                    mrz_result = reader.read(cropped)
                    if mrz_result:
                        raw_text = '\n'.join(mrz_result)
                        logger.info(f"âœ“ ReadMRZ extracted {len(raw_text)} chars")
                        return raw_text
                else:
                    logger.info("ReadMRZ: No MRZ region detected")
            except Exception as e:
                logger.warning(f"ReadMRZ failed: {e}")

        # PRIORITY 2: Try passport-mrz-extractor
        if passport_mrz_extractor_available:
            try:
                logger.info("Attempting passport-mrz-extractor...")
                result = passport_mrz_extractor.read_mrz(tmp_path)
                if result and isinstance(result, dict):
                    raw_mrz = result.get('raw_text') or result.get('mrz_text')
                    if raw_mrz:
                        logger.info(f"âœ“ passport-mrz-extractor extracted {len(raw_mrz)} chars")
                        return raw_mrz
            except Exception as e:
                logger.warning(f"passport-mrz-extractor failed: {e}")

        logger.warning("Both MRZ engines failed to extract text")
        return ""
        
    except Exception as e:
        logger.exception(f"MRZ text extraction error: {e}")
        return ""
    finally:
        if tmp_path and os.path.exists(tmp_path):
            try:
                os.remove(tmp_path)
            except Exception as cleanup_error:
                logger.warning(f"Failed to cleanup temp file {tmp_path}: {cleanup_error}")


def extract_structured_from_mrz(image: np.ndarray) -> Dict[str, Any]:
    """Extract structured data from MRZ using ReadMRZ and passport-mrz-extractor"""
    structured_data = {
        "prenom": None,
        "nom": None,
        "date_naissance": None,
        "lieu_naissance": None,
        "numero_carte": None,
        "date_expiration": None,
        "can": None
    }
    
    tmp_path = None
    try:
        with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as tmp:
            tmp_path = tmp.name
            success = cv2.imwrite(tmp_path, image, [cv2.IMWRITE_JPEG_QUALITY, 95])
            if not success:
                logger.error(f"Failed to save image to {tmp_path}")
                return structured_data

        # PRIORITY 1: Try passport-mrz-extractor (best for structured output)
        if passport_mrz_extractor_available:
            try:
                logger.info("Attempting passport-mrz-extractor structured extraction...")
                result = passport_mrz_extractor.read_mrz(tmp_path)
                if result and isinstance(result, dict):
                    # Map fields
                    if result.get('name') or result.get('given_name') or result.get('given_names'):
                        structured_data['prenom'] = str(result.get('name') or result.get('given_name') or result.get('given_names'))
                    if result.get('surname'):
                        structured_data['nom'] = str(result['surname'])
                    if result.get('birth_date') or result.get('date_of_birth'):
                        dob = str(result.get('birth_date') or result.get('date_of_birth'))
                        structured_data['date_naissance'] = dob.replace('-', '')
                    if result.get('document_number') or result.get('doc_number'):
                        structured_data['numero_carte'] = str(result.get('document_number') or result.get('doc_number'))
                    if result.get('expiry_date') or result.get('expiration_date'):
                        expiry = str(result.get('expiry_date') or result.get('expiration_date'))
                        structured_data['date_expiration'] = expiry.replace('-', '')
                    if result.get('nationality'):
                        structured_data['lieu_naissance'] = str(result['nationality'])
                    
                    extracted_count = sum(1 for v in structured_data.values() if v is not None)
                    if extracted_count >= 3:
                        logger.info(f"âœ“ passport-mrz-extractor successfully extracted {extracted_count} fields")
                        return structured_data
            except Exception as e:
                logger.warning(f"passport-mrz-extractor structured extraction failed: {e}")

        # PRIORITY 2: Try ReadMRZ
        if readmrz_available:
            try:
                logger.info("Attempting ReadMRZ structured extraction...")
                detector = MrzDetector()
                reader = MrzReader()
                
                mrz_image = detector.read(tmp_path)
                if mrz_image is not None:
                    cropped = detector.crop_area(mrz_image)
                    mrz_result = reader.process(cropped)
                    if mrz_result:
                        # Map fields
                        if mrz_result.get('name'):
                            structured_data['prenom'] = mrz_result['name']
                        if mrz_result.get('surname'):
                            structured_data['nom'] = mrz_result['surname']
                        if mrz_result.get('birth_date'):
                            structured_data['date_naissance'] = mrz_result['birth_date']
                        if mrz_result.get('document_number'):
                            structured_data['numero_carte'] = mrz_result['document_number']
                        if mrz_result.get('expiry_date'):
                            structured_data['date_expiration'] = mrz_result['expiry_date']
                        if mrz_result.get('nationality'):
                            structured_data['can'] = mrz_result['nationality']
                        
                        extracted_count = sum(1 for v in structured_data.values() if v is not None)
                        if extracted_count >= 3:
                            logger.info(f"ReadMRZ structured extraction successful: {extracted_count} fields")
                            return structured_data
            except Exception as e:
                logger.warning(f"ReadMRZ structured extraction failed: {e}")
        
        extracted_count = sum(1 for v in structured_data.values() if v is not None)
        logger.info(f"Final extraction: {extracted_count} fields from MRZ")
        return structured_data
        
    except Exception as e:
        logger.exception(f"MRZ structured extraction error: {e}")
        return structured_data
    finally:
        if tmp_path and os.path.exists(tmp_path):
            try:
                os.remove(tmp_path)
            except Exception as cleanup_error:
                logger.warning(f"Failed to cleanup temp file {tmp_path}: {cleanup_error}")


def detect_deepfake(image: np.ndarray) -> dict:
    """Detect deepfake"""
    if not deepfake_available:
        return {'is_real': True, 'confidence': 0.5, 'model_available': False}
    
    try:
        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        pil_image = Image.fromarray(rgb_image)
        inputs = deepfake_processor(images=pil_image, return_tensors="pt")
        
        if GPU_AVAILABLE:
            inputs = {k: v.to('cuda') for k, v in inputs.items()}
        
        with torch.no_grad():
            outputs = deepfake_model(**inputs)
            logits = outputs.logits
            probs = torch.softmax(logits, dim=1)
        
        predicted_class = logits.argmax(-1).item()
        confidence = probs[0][predicted_class].item()
        label = deepfake_model.config.id2label[predicted_class]
        
        is_real = label.lower() == "real"
        
        return {
            'is_real': bool(is_real),
            'confidence': float(confidence),
            'label': label,
            'model_available': True
        }
    except Exception as e:
        logger.exception(f"Deepfake detection error: {e}")
        return {'is_real': True, 'confidence': 0.5, 'error': str(e)}


# ============================================================================
# FASTAPI APP & SETUP
# ============================================================================
app = FastAPI(
    title="Enhanced ID Verification API",
    description="Production-grade ID verification with advanced anti-spoofing",
    version="2.0.0"
)

# Load deepfake model
logger.info("Loading models")

try:
    deepfake_model_name = "dima806/deepfake_vs_real_image_detection"
    deepfake_processor = AutoImageProcessor.from_pretrained(deepfake_model_name)
    deepfake_model = AutoModelForImageClassification.from_pretrained(deepfake_model_name)
    if GPU_AVAILABLE:
        deepfake_model = deepfake_model.to('cuda')
    deepfake_model.eval()
    deepfake_available = True
    logger.info(f"âœ“ Deepfake detection loaded ({DEVICE_MODE.upper()})")
except Exception as e:
    logger.exception(f"âš ï¸  Deepfake detection failed to load: {e}")
    deepfake_available = False

# Initialize enhanced components
liveness_detector = AdvancedLivenessDetector()
face_matcher = EnsembleFaceMatcher(use_gpu=GPU_AVAILABLE)
doc_checker = DocumentAuthenticityChecker()

logger.info("âœ“ Enhanced components initialized")
logger.info("=" * 70)

# CORS
ALLOWED_ORIGINS = os.getenv("ALLOWED_ORIGINS", "*").split(",")
app.add_middleware(
    CORSMiddleware,
    allow_origins=ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["POST", "GET"],
    allow_headers=["*"],
)

@app.exception_handler(Exception)
async def generic_exception_handler(request: Request, exc: Exception):
    logger.exception(f"Unhandled exception: {exc}")
    return JSONResponse(status_code=500, content={"detail": "Internal server error"})


# ============================================================================
# RESPONSE MODELS
# ============================================================================
class VerificationResponse(BaseModel):
    verification_id: str
    timestamp: str
    face_match: bool
    confidence: float
    distance: float
    extracted_text: Optional[str]
    structured_data: Optional[Dict[str, Any]] = None
    status: str
    message: str
    liveness_check: Optional[dict] = None
    deepfake_check: Optional[dict] = None
    document_authenticity: Optional[dict] = None
    overall_confidence: Optional[float] = None
    warnings: Optional[List[str]] = None
    errors: Optional[List[str]] = None


class HealthResponse(BaseModel):
    status: str
    version: str
    device: Optional[str] = None
    gpu_available: Optional[bool] = None


# ============================================================================
# HELPER FUNCTIONS
# ============================================================================
def read_image_file(file_bytes: bytes) -> np.ndarray:
    """Convert uploaded file bytes to OpenCV image"""
    try:
        image = Image.open(io.BytesIO(file_bytes))
        return cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Invalid image: {str(e)}")


# ============================================================================
# ENHANCED VERIFICATION PIPELINE
# ============================================================================
class EnhancedVerificationPipeline:
    """Complete verification pipeline with all checks"""
    
    def __init__(self):
        self.liveness_detector = liveness_detector
        self.face_matcher = face_matcher
        self.doc_checker = doc_checker
    
    async def verify_identity(
        self,
        id_document: np.ndarray,
        selfie: np.ndarray,
        structured_data: Optional[Dict] = None
    ) -> Dict:
        """Complete identity verification - runs ALL checks regardless of failures"""
        verification_result = {
            'status': VerificationStatus.ERROR.value,
            'overall_confidence': 0.0,
            'checks': {},
            'warnings': [],
            'errors': [],
            'message': 'Verification incomplete'
        }
        
        try:
            # PHASE 1: PRE-FLIGHT CHECKS
            logger.info("Phase 1: Pre-flight quality checks")
            try:
                preflight = await self._preflight_checks(id_document, selfie)
                verification_result['checks']['preflight'] = preflight
                
                if not preflight.get('passed', False):
                    verification_result['errors'].append('Image quality checks failed')
                
                # Add quality warnings
                if preflight.get('checks', {}).get('id_quality', {}).get('quality_score', 100) < 70:
                    verification_result['warnings'].append('ID document quality is low')
                if preflight.get('checks', {}).get('selfie_quality', {}).get('quality_score', 100) < 70:
                    verification_result['warnings'].append('Selfie quality is low')
            except Exception as e:
                logger.exception(f"Preflight check error: {e}")
                verification_result['errors'].append(f'Preflight check failed: {str(e)}')
            
            # PHASE 2: LIVENESS DETECTION
            logger.info("Phase 2: Advanced liveness detection")
            try:
                liveness_result = await run_in_threadpool(
                    self.liveness_detector.comprehensive_check, 
                    selfie
                )
                verification_result['checks']['liveness'] = liveness_result
                
                if not liveness_result.get('is_live', False):
                    verification_result['errors'].append(
                        f"Liveness check failed (score: {liveness_result.get('liveness_score', 0):.2f})"
                    )
                elif liveness_result.get('liveness_score', 0) < config.liveness_score_high:
                    verification_result['warnings'].append('Liveness confidence is medium')
            except Exception as e:
                logger.exception(f"Liveness check error: {e}")
                verification_result['errors'].append(f'Liveness check failed: {str(e)}')
            
            # PHASE 3: DEEPFAKE DETECTION
            logger.info("Phase 3: Deepfake detection")
            try:
                deepfake_result = await run_in_threadpool(detect_deepfake, selfie)
                verification_result['checks']['deepfake'] = deepfake_result
                
                if not deepfake_result.get('is_real', True):
                    verification_result['errors'].append('Potential deepfake detected')
                elif deepfake_result.get('confidence', 1.0) < config.deepfake_confidence_min:
                    verification_result['warnings'].append('Deepfake confidence is low')
            except Exception as e:
                logger.exception(f"Deepfake check error: {e}")
                verification_result['errors'].append(f'Deepfake check failed: {str(e)}')
            
            # PHASE 4: DOCUMENT AUTHENTICITY
            logger.info("Phase 4: Document authenticity")
            try:
                doc_auth_result = await run_in_threadpool(
                    self.doc_checker.comprehensive_document_check,
                    id_document,
                    structured_data
                )
                verification_result['checks']['document_authenticity'] = doc_auth_result
                
                if not doc_auth_result.get('is_authentic', True):
                    verification_result['errors'].append('Document authenticity check failed')
                elif doc_auth_result.get('authenticity_score', 100) < config.authenticity_score_high:
                    verification_result['warnings'].append('Document authenticity confidence is medium')
            except Exception as e:
                logger.exception(f"Document authenticity check error: {e}")
                verification_result['errors'].append(f'Document authenticity check failed: {str(e)}')
            
            # PHASE 5: FACE MATCHING (ENSEMBLE)
            logger.info("Phase 5: Ensemble face matching")
            try:
                face_match_result = await run_in_threadpool(
                    self.face_matcher.ensemble_match,
                    id_document,
                    selfie
                )
                verification_result['checks']['face_match'] = face_match_result
                
                if not face_match_result.get('matched', False):
                    verification_result['errors'].append('Face matching failed')
            except Exception as e:
                logger.exception(f"Face matching error: {e}")
                verification_result['errors'].append(f'Face matching failed: {str(e)}')
            
            # PHASE 6: FINAL DECISION (always runs)
            logger.info("Phase 6: Final decision")
            final_decision = self._make_final_decision(verification_result)
            verification_result.update(final_decision)
            
            return verification_result
            
        except Exception as e:
            logger.exception(f"Verification pipeline error: {e}")
            verification_result['status'] = VerificationStatus.ERROR.value
            verification_result['errors'].append(f"System error: {str(e)}")
            verification_result['message'] = f"Critical system error: {str(e)}"
            return verification_result
    
    async def _preflight_checks(self, id_document: np.ndarray, selfie: np.ndarray) -> Dict:
        """Pre-flight quality checks"""
        checks = {}
        
        try:
            id_h, id_w = id_document.shape[:2]
            selfie_h, selfie_w = selfie.shape[:2]
            
            checks['id_resolution'] = {
                'width': int(id_w),
                'height': int(id_h),
                'passed': bool(id_w >= 640 and id_h >= 480)
            }
            
            checks['selfie_resolution'] = {
                'width': int(selfie_w),
                'height': int(selfie_h),
                'passed': bool(selfie_w >= 480 and selfie_h >= 640)
            }
            
            checks['id_is_color'] = {
                'value': bool(len(id_document.shape) == 3),
                'passed': bool(len(id_document.shape) == 3)
            }
            
            checks['selfie_is_color'] = {
                'value': bool(len(selfie.shape) == 3),
                'passed': bool(len(selfie.shape) == 3)
            }
            
            # Quality metrics
            id_quality = await run_in_threadpool(
                self.face_matcher.get_quality_metrics, 
                id_document
            )
            selfie_quality = await run_in_threadpool(
                self.face_matcher.get_quality_metrics,
                selfie
            )
            
            checks['id_quality'] = id_quality
            checks['selfie_quality'] = selfie_quality
            
            all_passed = all(
                check.get('passed', False)
                for check in checks.values()
                if isinstance(check, dict) and 'passed' in check
            )
            
            return {
                'passed': bool(all_passed),
                'checks': checks
            }
        except Exception as e:
            logger.exception(f"Preflight checks failed: {e}")
            return {'passed': False, 'error': str(e)}
    
    def _make_final_decision(self, verification_result: Dict) -> Dict:
        """Make final verification decision based on all checks"""
        try:
            checks = verification_result['checks']
            warnings = verification_result['warnings']
            errors = verification_result['errors']
            
            # If critical errors exist, reject immediately
            if errors:
                critical_errors = [
                    'Liveness check failed',
                    'Potential deepfake detected',
                    'Face matching failed'
                ]
                has_critical_error = any(
                    any(critical in error for critical in critical_errors)
                    for error in errors
                )
                
                if has_critical_error:
                    # Calculate partial confidence for reporting
                    liveness_score = checks.get('liveness', {}).get('liveness_score', 0) * 100
                    face_confidence = checks.get('face_match', {}).get('confidence', 0)
                    authenticity_score = checks.get('document_authenticity', {}).get('authenticity_score', 0)
                    deepfake_confidence = checks.get('deepfake', {}).get('confidence', 0) * 100
                    
                    # Average available scores
                    scores = [s for s in [liveness_score, face_confidence, authenticity_score, deepfake_confidence] if s > 0]
                    overall_confidence = sum(scores) / len(scores) if scores else 0.0
                    
                    return {
                        'status': VerificationStatus.REJECTED.value,
                        'overall_confidence': float(overall_confidence),
                        'message': f"âŒ Verification rejected: {'; '.join(errors)}",
                        'recommendation': 'Do not proceed - verification failed security checks'
                    }
            
            # Extract key scores (handle missing checks gracefully)
            liveness_score = checks.get('liveness', {}).get('liveness_score', 0)
            face_confidence = checks.get('face_match', {}).get('confidence', 0)
            authenticity_score = checks.get('document_authenticity', {}).get('authenticity_score', 50)
            deepfake_confidence = checks.get('deepfake', {}).get('confidence', 0.5)
            
            # Calculate weighted overall confidence
            weights = {
                'liveness': 0.25,
                'face_match': 0.35,
                'authenticity': 0.25,
                'deepfake': 0.15
            }
            
            overall_confidence = (
                liveness_score * weights['liveness'] * 100 +
                face_confidence * weights['face_match'] +
                authenticity_score * weights['authenticity'] +
                deepfake_confidence * weights['deepfake'] * 100
            )
            
            # Decision logic with graduated responses
            if overall_confidence >= 85.0 and not warnings:
                status = VerificationStatus.APPROVED
                message = "âœ… Identity verified successfully with high confidence"
            
            elif overall_confidence >= 75.0:
                if len(warnings) > 0:
                    status = VerificationStatus.MANUAL_REVIEW
                    message = f"âš ï¸ Manual review recommended: {', '.join(warnings)}"
                else:
                    status = VerificationStatus.APPROVED
                    message = "âœ… Identity verified successfully"
            
            elif overall_confidence >= 65.0:
                status = VerificationStatus.MANUAL_REVIEW
                message = "âš ï¸ Verification requires manual review - confidence below high threshold"
            
            else:
                status = VerificationStatus.REJECTED
                message = "âŒ Verification failed - overall confidence too low"
            
            return {
                'status': status.value,
                'overall_confidence': float(overall_confidence),
                'message': message,
                'recommendation': self._get_recommendation(status, overall_confidence, warnings)
            }
        except Exception as e:
            logger.exception(f"Final decision error: {e}")
            return {
                'status': VerificationStatus.ERROR.value,
                'overall_confidence': 0.0,
                'message': f'Error making final decision: {str(e)}',
                'recommendation': 'System error - retry verification'
            }
    
    def _get_recommendation(self, status: VerificationStatus, confidence: float, warnings: list) -> str:
        """Get actionable recommendation"""
        if status == VerificationStatus.APPROVED:
            return "Proceed with onboarding"
        elif status == VerificationStatus.MANUAL_REVIEW:
            reasons = []
            if confidence < 80:
                reasons.append("confidence below 80%")
            if warnings:
                reasons.append(f"{len(warnings)} warning(s)")
            return f"Human review required: {', '.join(reasons)}"
        elif status == VerificationStatus.REJECTED:
            return "Do not proceed - verification failed security checks"
        else:
            return "System error - retry verification"


# Initialize pipeline
pipeline = EnhancedVerificationPipeline()


# ============================================================================
# API ENDPOINTS
# ============================================================================
@app.get("/", response_model=HealthResponse)
async def root():
    """Health check endpoint"""
    return {
        "status": "online",
        "version": "2.0.0"
    }

@app.get("/health", response_model=HealthResponse)
async def health_check():
    """Detailed health check"""
    return {
        "status": "healthy",
        "version": "2.0.0",
        "device": DEVICE_MODE,
        "gpu_available": GPU_AVAILABLE
    }

@app.post("/api/v1/verify", response_model=VerificationResponse)
async def verify_identity(
    id_document: UploadFile = File(..., description="ID card/passport/driver's license image"),
    selfie: UploadFile = File(..., description="User selfie image")
):
    """
    Enhanced identity verification with multi-layered security
    
    Features:
    - Advanced liveness detection (6+ checks)
    - Ensemble face matching
    - Document authenticity validation
    - Deepfake detection
    - Risk-based graduated responses
    """
    
    verification_id = str(uuid.uuid4())
    timestamp = datetime.now(timezone.utc).isoformat()
    
    try:
        # Read images
        id_bytes = await id_document.read()
        selfie_bytes = await selfie.read()
        id_image = read_image_file(id_bytes)
        selfie_image = read_image_file(selfie_bytes)
        
        # Extract structured data from ID
        structured_data = await run_in_threadpool(extract_structured_from_mrz, id_image)
        extracted_text = await run_in_threadpool(extract_text_from_image, id_image)
        
        # Run enhanced verification pipeline
        result = await pipeline.verify_identity(
            id_document=id_image,
            selfie=selfie_image,
            structured_data=structured_data
        )
        
        # Build response
        face_match_data = result['checks'].get('face_match', {})
        
        return VerificationResponse(
            verification_id=verification_id,
            timestamp=timestamp,
            face_match=face_match_data.get('matched', False),
            confidence=face_match_data.get('confidence', 0.0),
            distance=face_match_data.get('individual_results', {}).get('face_recognition', {}).get('distance', 1.0),
            extracted_text=extracted_text if extracted_text else None,
            structured_data=structured_data if any(structured_data.values()) else None,
            status=result['status'],
            message=result['message'],
            liveness_check=result['checks'].get('liveness'),
            deepfake_check=result['checks'].get('deepfake'),
            document_authenticity=result['checks'].get('document_authenticity'),
            overall_confidence=result.get('overall_confidence'),
            warnings=result.get('warnings') if result.get('warnings') else None,
            errors=result.get('errors') if result.get('errors') else None
        )
        
    except HTTPException as he:
        raise he
    except Exception as e:
        logger.exception(f"Verification endpoint error: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Verification failed: {str(e)}"
        )

@app.post("/api/v1/extract-text")
async def extract_document_text(
    document: UploadFile = File(..., description="Document image for text extraction")
):
    """Extract text from document using MRZ engines"""
    try:
        logger.info(f"Received extract-text request for file: {document.filename}")
        doc_bytes = await document.read()
        logger.info(f"Read {len(doc_bytes)} bytes from uploaded file")
        doc_image = await run_in_threadpool(read_image_file, doc_bytes)
        logger.info(f"Image shape: {doc_image.shape if doc_image is not None else 'None'}")
        
        # Extract both text and structured data
        text = await run_in_threadpool(extract_text_from_image, doc_image)
        structured_data = await run_in_threadpool(extract_structured_from_mrz, doc_image)
        
        logger.info(f"Extracted text length: {len(text) if text else 0}")
        logger.info(f"Structured data: {structured_data}")
        
        # MRZ detection logic
        mrz_detected = bool(text and text.strip())
        has_structured_data = any(v is not None for v in structured_data.values())
        
        response = {
            "success": True,
            "extracted_text": text if text and text.strip() else None,
            "structured_data": structured_data if has_structured_data else None,
            "mrz_detected": mrz_detected,
            "fields_extracted": sum(1 for v in structured_data.values() if v is not None),
            "message": (
                f"MRZ detected - {sum(1 for v in structured_data.values() if v is not None)} fields extracted" 
                if mrz_detected 
                else "No MRZ detected in the image. Please ensure the document is a passport, ID card, or visa with MRZ zone visible."
            ),
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "ocr_engines": {
                "readmrz_available": readmrz_available,
                "passport_mrz_extractor_available": passport_mrz_extractor_available
            }
        }
        logger.info(f"Returning response: {response}")
        return response
    except Exception as e:
        logger.exception(f"Text extraction endpoint error: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Text extraction failed: {str(e)}"
        )

@app.get("/api/v1/config")
async def get_config():
    """Get current verification configuration"""
    return {
        "liveness_score_min": config.liveness_score_min,
        "liveness_score_high": config.liveness_score_high,
        "face_match_confidence_min": config.face_match_confidence_min,
        "face_match_confidence_high": config.face_match_confidence_high,
        "authenticity_score_min": config.authenticity_score_min,
        "deepfake_confidence_min": config.deepfake_confidence_min,
        "image_quality_min": config.image_quality_min,
        "ocr_engines": {
            "readmrz_available": readmrz_available,
            "passport_mrz_extractor_available": passport_mrz_extractor_available
        },
        "deepfake_detection_available": deepfake_available,
        "device_mode": DEVICE_MODE
    }


# ============================================================================
# BACKGROUND MONITORING
# ============================================================================
_monitor_thread = None
_monitor_running = threading.Event()

def resource_monitor(interval: float = 10.0):
    """Background resource monitoring"""
    logger.info("Resource monitor started")
    proc = psutil.Process(os.getpid())
    _monitor_running.set()
    try:
        while _monitor_running.is_set():
            try:
                cpu = psutil.cpu_percent(interval=None)
                mem = psutil.virtual_memory()
                rss = proc.memory_info().rss / (1024 * 1024)  # MB
                logger.info(f"Resource Usage - CPU: {cpu:.1f}%, MEM: {mem.percent:.1f}%, RSS: {rss:.1f}MB")
            except Exception as e:
                logger.exception(f"Resource monitor error: {e}")
            time.sleep(interval)
    finally:
        logger.info("Resource monitor stopped")

@app.on_event("startup")
def _on_startup():
    global _monitor_thread
    logger.info("ðŸš€ Enhanced ID Verification API started")
    logger.info(f"Device: {DEVICE_MODE.upper()}")
    logger.info(f"ReadMRZ available: {readmrz_available}")
    logger.info(f"passport-mrz-extractor available: {passport_mrz_extractor_available}")
    logger.info(f"Deepfake detection available: {deepfake_available}")
    logger.info(f"Liveness threshold: {config.liveness_score_min}")
    logger.info(f"Face match threshold: {config.face_match_confidence_min}%")
    logger.info("Starting resource monitor...")
    _monitor_thread = threading.Thread(target=resource_monitor, args=(15.0,), daemon=True)
    _monitor_thread.start()

@app.on_event("shutdown")
def _on_shutdown():
    global _monitor_thread
    logger.info("Shutting down Enhanced ID Verification API")
    _monitor_running.clear()
    if _monitor_thread is not None:
        _monitor_thread.join(timeout=2.0)


# ============================================================================
# MAIN
# ============================================================================
if __name__ == "__main__":
    nest_asyncio.apply()
    uvicorn.run(app, host="0.0.0.0", port=8000)

